<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Peter Wooldridge's Blog - Machine Learning</title><link href="https://peterwooldridge.me/" rel="alternate"></link><link href="https://peterwooldridge.me/feeds/machine-learning.atom.xml" rel="self"></link><id>https://peterwooldridge.me/</id><updated>2019-09-04T11:56:00+01:00</updated><subtitle>I'm a Data Scientist with Type 1 Diabetes. Most of the time I'll write about one or the other.</subtitle><entry><title>Support Vector Machines (Part 1)</title><link href="https://peterwooldridge.me/posts/2019/Sep/04/svm_1/" rel="alternate"></link><published>2019-09-04T11:56:00+01:00</published><updated>2019-09-04T11:56:00+01:00</updated><author><name>Peter Wooldridge</name></author><id>tag:peterwooldridge.me,2019-09-04:/posts/2019/Sep/04/svm_1/</id><summary type="html">&lt;p&gt;Support Vector Machines (SVMs) are a versatile classification algorithm that should be a staple in every data scientists toolbox. In this first of a series of posts, my goal is to describe the intuition behind SVMs what makes them such a powerful technique for classification.&lt;/p&gt;
&lt;p&gt;Suppose we want to classify …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Support Vector Machines (SVMs) are a versatile classification algorithm that should be a staple in every data scientists toolbox. In this first of a series of posts, my goal is to describe the intuition behind SVMs what makes them such a powerful technique for classification.&lt;/p&gt;
&lt;p&gt;Suppose we want to classify the red dots from the blue in the figure below. Plotted on the axes are an orange, black and green hyperplane. All three perfectly separate the red and blue classes. So which one is the best choice to split our data?&lt;/p&gt;
&lt;p align="center"&gt;
   &lt;img src="images/multiple_hyperplanes.png" alt="drawing" width="500"/&gt;  
&lt;/p&gt;

&lt;p&gt;The hardest points to classify are those sat closest to the hyperplane. Therefore, a decision boundary that creates a large gap between the classes is preferable because new data points are more likely to be correctly classified. The SVM defines this criterion as finding a decision boundary that is maximally far away from any data point. The distance between the decision boundary and the closest data point determines the margin of the classifier.&lt;/p&gt;
&lt;p&gt;The figure below shows the data being separated by the largest margin decision boundary. The maximum margin decision boundary is defined by two parallel hyperplanes, one that goes through the positive data points closest to the decision boundary and one that goes through the negative points closest to the decision boundary. These are known as the support vectors.&lt;/p&gt;
&lt;p align="center"&gt;
   &lt;img src="images/maximal_margin.png" alt="Drawing" width="500"/&gt;
&lt;/p&gt;

&lt;p&gt;Mathematically, we can summarise what we have described so far.&lt;/p&gt;
&lt;p&gt;Suppose we are given &lt;span class="math"&gt;\(N\)&lt;/span&gt; training vectors &lt;span class="math"&gt;\(\{(x^{(i)}, y^{(i)}); i=0, \dots, N\}, \text{ where } x ∈ \mathbb{R}^{D}, y ∈ \{−1, 1\}\)&lt;/span&gt;. We want to learn a set of weights &lt;span class="math"&gt;\(w\)&lt;/span&gt; and &lt;span class="math"&gt;\(b\)&lt;/span&gt; such that the linear combination of weights and input data predicts the value of y.&lt;/p&gt;
&lt;div class="math"&gt;$$
h_{w,b}(x) =
     \begin{cases}
       1 &amp;amp;\quad\text{if }w^{T} x + b &amp;gt;= 0\\
       -1 &amp;amp;\quad\text{otherwise}
     \end{cases}
$$&lt;/div&gt;
&lt;p&gt;In the two dimensional case, our decision boundary &lt;span class="math"&gt;\(w^{T} x + b = 0\)&lt;/span&gt; is simply a line with the regions above and below it represented by &lt;span class="math"&gt;\(w^{T}x + b &amp;gt; 0\)&lt;/span&gt; and &lt;span class="math"&gt;\(w^{T}x + b &amp;lt; 0\)&lt;/span&gt;.&lt;/p&gt;
&lt;p align="center"&gt;
   &lt;img src="images/decision_boundary.png" alt="Drawing" width="500"/&gt;
&lt;/p&gt;

&lt;h3&gt;Distance between points and the hyperplane&lt;/h3&gt;
&lt;p&gt;We know that we want to find the values of &lt;span class="math"&gt;\(w\)&lt;/span&gt; and &lt;span class="math"&gt;\(b\)&lt;/span&gt; that provide the widest margin. Therefore, we need a way to measure the distance between a given point and the hyperplane. Let's define &lt;span class="math"&gt;\(\gamma^{(i)}\)&lt;/span&gt; to be the distance between the &lt;span class="math"&gt;\(i^{th}\)&lt;/span&gt; training observation &lt;span class="math"&gt;\(x^{(i)}\)&lt;/span&gt; and our hyperplane.&lt;/p&gt;
&lt;p&gt;Consider the decision boundary shown in the figure below. If we define &lt;span class="math"&gt;\(x_{0}\)&lt;/span&gt; to be a vector on the hyperplane. Then the &lt;span class="math"&gt;\(x^{(i)} - x_{0}\)&lt;/span&gt; represents a vector from &lt;span class="math"&gt;\(x^{(i)}\)&lt;/span&gt; to the hyperplane. The dotted black line from &lt;span class="math"&gt;\(x^{(i)}\)&lt;/span&gt; to the hyperplane represents the vector whose distance is the shortest to the hyperplane. This dotted line forms a right-angled triangle with the hyperplane and we can label the unknown angle at the top of our triangle &lt;span class="math"&gt;\(\theta\)&lt;/span&gt;. The vector &lt;span class="math"&gt;\(w^{*}\)&lt;/span&gt; represents the unit vector perpendicular to the hyperplane.&lt;/p&gt;
&lt;p align="center"&gt;
   &lt;img src="images/svm_distance_to_hyperplane.png" alt="Drawing" width="500"/&gt;
&lt;/p&gt;

&lt;p&gt;Using trigonometry, and setting &lt;span class="math"&gt;\(f = x^{(i)} - x_{0}\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\cos{\theta} = \dfrac{\text{adjacent}}{\text{hypothenuse}}\\
\implies \cos{\theta} = \dfrac{\gamma^{(i)}}{\|f\|}\\
\implies \|f\|\cos{\theta} = \gamma^{(i)}\\
\implies \dfrac{\|w^{*}\|}{\|w^{*}\|}\|f\|\cos{\theta} = \gamma^{(i)}\\
\implies fw^{*} = \gamma^{(i)}\\
\implies \dfrac{(x^{(i)} - x_{0})w}{\|w\|} = \gamma^{(i)}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;and then using &lt;span class="math"&gt;\(wx_{0} = -b\)&lt;/span&gt;, since &lt;span class="math"&gt;\(x_{0}\)&lt;/span&gt; lies on the hyperplane, we have:&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\implies \dfrac{wx^{(i)} + b}{\|w\|} = \gamma^{(i)}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We will see below how this distance is used in the definitions of the Functional and Geometric margins defined below.&lt;/p&gt;
&lt;h3&gt;Functional and Geometric Margins&lt;/h3&gt;
&lt;p&gt;Given a training example &lt;span class="math"&gt;\((x^{(i)}, y^{(i)})\)&lt;/span&gt;, we define the functional margin of &lt;span class="math"&gt;\((w, b)\)&lt;/span&gt; with
respect to a training example as:&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\hat{\gamma}^{(i)} = y^{(i)}(w^{T} x^{(i)} + b)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The functional margin serves as a test function to determine whether a given training point is classified correctly. For a training example to be correctly classified &lt;span class="math"&gt;\(\hat{\gamma}^{(i)} \geq 0\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;One problem with the functional margin is that it can be affected by an arbitrary scaling of &lt;span class="math"&gt;\(w\)&lt;/span&gt; and &lt;span class="math"&gt;\(b\)&lt;/span&gt;. That brings us onto the definition of the geometric margin:&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\gamma^{(i)} = \hat{\gamma}^{(i)}/\|w\|\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The geometric margin is telling you not only if a point is properly classified or not, but the magnitude of that distance in term of units of |w|. It is invariant to any scaling of &lt;span class="math"&gt;\(w\)&lt;/span&gt; or &lt;span class="math"&gt;\(b\)&lt;/span&gt; which will be important later. The geometric margin should look familiar as the distance between a training point and our hyperplane that we derived in the previous section multiplied by the label &lt;span class="math"&gt;\(y^{(i)}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Given a training set&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(S = \{(x^{(i)}, y^{(i)}); i=1 \dotsc n\}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;we define the geometric margin of &lt;span class="math"&gt;\((w,b)\)&lt;/span&gt; with respect to &lt;span class="math"&gt;\(S\)&lt;/span&gt; to be the smallest of the geometric margins on the individual training examples:&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\gamma = \min_{i=1 \dotsc n} \gamma ^ {(i)}\)&lt;/span&gt;&lt;/p&gt;
&lt;h3&gt;The optimal margin classifier&lt;/h3&gt;
&lt;p&gt;In order to find the widest margin classifier, we want to maximise the geometric margin whilst still correctly classifying all our training examples. This can be formulated as the following optimisation problem:&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\max_{w, b} \gamma \quad\)&lt;/span&gt; s.t. &lt;span class="math"&gt;\(\quad \dfrac{y^{(i)}(w^{T} x^{(i)} + b)}{\|w\|}\geq \gamma \text{ for } i=1 \dotsc n\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;It turns out that the above problem is hard to optimise. Therefore, we convert it to any equivalent problem that happends to be easier to solve. For any solution to satisfy the above equation, any positively scaled multiple will also, due to the fact that the geometric margin is invariant to scaling of &lt;span class="math"&gt;\(w\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Therefore, we can scale &lt;span class="math"&gt;\(w\)&lt;/span&gt; in such a way that &lt;span class="math"&gt;\(\|w\| = \dfrac{1}{\gamma}\)&lt;/span&gt;. Also note that maximising &lt;span class="math"&gt;\(\dfrac{1}{\|w\|}\)&lt;/span&gt; is the same as minimising &lt;span class="math"&gt;\(\|w\|\)&lt;/span&gt; which is the same as minimising &lt;span class="math"&gt;\(\dfrac{1}{2}\|w\|^{2}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Thus, we can reformulate the optimisation problem as:  &lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\min_{w, b} \dfrac{1}{2}\|w\|^{2} \quad\)&lt;/span&gt; s.t. &lt;span class="math"&gt;\(\quad y^{(i)}(w^{T} x^{(i)} + b)\geq 1 \text{ for } i=1 \dotsc n\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This optimisation problem is known as a quadratic optimisation problem which is easier to solve. The solution to this optimisation problem will be the topic for a future post.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content></entry><entry><title>Visualising networks in R using atomic plot functions</title><link href="https://peterwooldridge.me/posts/2017/Sep/28/heatmaps_in_r/" rel="alternate"></link><published>2017-09-28T21:13:00+01:00</published><updated>2017-09-28T21:13:00+01:00</updated><author><name>Peter Wooldridge</name></author><id>tag:peterwooldridge.me,2017-09-28:/posts/2017/Sep/28/heatmaps_in_r/</id><summary type="html">&lt;p&gt;One of the most natural ways to visualise a social network is a network diagram which consists of a series of dots representing the entity in the network and lines representing the relationships between the entities. This type of visualisation looks as follows:&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img alt="" src="images/standard-network-plot.png" /&gt;
&lt;/div&gt;
&lt;p&gt;We can encode community information to this …&lt;/p&gt;</summary><content type="html">&lt;p&gt;One of the most natural ways to visualise a social network is a network diagram which consists of a series of dots representing the entity in the network and lines representing the relationships between the entities. This type of visualisation looks as follows:&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img alt="" src="images/standard-network-plot.png" /&gt;
&lt;/div&gt;
&lt;p&gt;We can encode community information to this type of plot by colouring the nodes according to the communitiy memberships.&lt;/p&gt;
&lt;p&gt;As Mike Bostock &lt;a class="reference external" href="https://bost.ocks.org/mike/miserables/"&gt;showed&lt;/a&gt;, another interesting way to visualise a network is with the adjacency matrix. As a reminder the Adjacency matrix is defined as follows:&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
A_{ij} = \left\{
\begin{array}{lr}
1 &amp;amp; : \text{if }i\text{ connected to }j\\
0 &amp;amp; : \text{otherwise}
\end{array}
\right.
\end{equation*}
&lt;/div&gt;
&lt;p&gt;The usefullness of the visualisation of the adjacency matrix depends largely on the order of the rows and columns in the plot. By finding communities in the network, we can reorder the rows and columns of the adjacency matrix accordingly to produce a plot that looks as follows:&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img alt="" src="images/lesmis.png" /&gt;
&lt;/div&gt;
&lt;p&gt;In this post I show how to create the above plot using atomic plot functions in R. The coloured blocks down the diagonal of the plot represent the different communities in the network.&lt;/p&gt;
&lt;p&gt;To get started, the first thing we need is some data in a matrix object. We load the same Les Misérables data as used for the visualisation &lt;a class="reference external" href="https://bost.ocks.org/mike/miserables/"&gt;here&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nf"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;jsonlite&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nf"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;igraph&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;json_data&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;fromJSON&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;https://bost.ocks.org/mike/miserables/miserables.json&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The &lt;code&gt;fromJSON&lt;/code&gt; function reads the les miserables data into a list containing information about the nodes and edges in the graph. We extract two fields from the list, a vector of character names and the edge data&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;characters&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="n"&gt;json_data[[1]]&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;
&lt;span class="n"&gt;edges&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="n"&gt;json_data[[2]]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We can view these two objects:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nf"&gt;head&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;characters&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;[1]&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Myriel&amp;quot;&lt;/span&gt;          &lt;span class="s"&gt;&amp;quot;Napoleon&amp;quot;&lt;/span&gt;        &lt;span class="s"&gt;&amp;quot;Mlle.Baptistine&amp;quot;&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Mme.Magloire&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;[5]&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;CountessdeLo&amp;quot;&lt;/span&gt;    &lt;span class="s"&gt;&amp;quot;Geborand&amp;quot;&lt;/span&gt;

&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nf"&gt;head&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;edges&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;source&lt;/span&gt; &lt;span class="n"&gt;target&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;
&lt;span class="m"&gt;1&lt;/span&gt;      &lt;span class="m"&gt;1&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt;     &lt;span class="m"&gt;1&lt;/span&gt;
&lt;span class="m"&gt;2&lt;/span&gt;      &lt;span class="m"&gt;2&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt;     &lt;span class="m"&gt;8&lt;/span&gt;
&lt;span class="m"&gt;3&lt;/span&gt;      &lt;span class="m"&gt;3&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;10&lt;/span&gt;
&lt;span class="m"&gt;4&lt;/span&gt;      &lt;span class="m"&gt;3&lt;/span&gt;      &lt;span class="m"&gt;2&lt;/span&gt;     &lt;span class="m"&gt;6&lt;/span&gt;
&lt;span class="m"&gt;5&lt;/span&gt;      &lt;span class="m"&gt;4&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt;     &lt;span class="m"&gt;1&lt;/span&gt;
&lt;span class="m"&gt;6&lt;/span&gt;      &lt;span class="m"&gt;5&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt;     &lt;span class="m"&gt;1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The &lt;code&gt;edges&lt;/code&gt; object contains information about which node (source column) is connected to which (target column) and the co-occurence number (value column). This a succint way to represent a matrix as we only have rows for the non-zero matrix elements. Representing a matrix in this way is known as Triplet representation.&lt;/p&gt;
&lt;p&gt;Next, we convert each of the numeric columns of &lt;code&gt;edges&lt;/code&gt; into character names by iterating through each row of &lt;code&gt;edges&lt;/code&gt; and replacing the &lt;code&gt;source&lt;/code&gt; and &lt;code&gt;target&lt;/code&gt; numbers with the name of the character at that index of the characters array. We add one to the index to account for the fact that R indexes from one not zero.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;edges_w_names&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;t&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;apply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;edges&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;MARGIN&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nf"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="n"&gt;src_idx&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;as.numeric&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x[&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;source&amp;quot;&lt;/span&gt;&lt;span class="n"&gt;]&lt;/span&gt;&lt;span class="m"&gt;+1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;dest_idx&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;as.numeric&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x[&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;target&amp;quot;&lt;/span&gt;&lt;span class="n"&gt;]&lt;/span&gt;&lt;span class="m"&gt;+1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="nf"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;characters[src_idx]&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;characters[dest_idx]&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x[&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;value&amp;quot;&lt;/span&gt;&lt;span class="n"&gt;]&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;}))&lt;/span&gt;
&lt;span class="n"&gt;edges_w_names&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;as.data.frame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;edges_w_names&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stringsAsFactors&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;F&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nf"&gt;colnames&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;edges_w_names&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;source&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;target&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;value&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;edges_w_names&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;&lt;span class="n"&gt;source&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;as.character&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;edges_w_names&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;&lt;span class="n"&gt;source&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;edges_w_names&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;&lt;span class="n"&gt;target&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;as.character&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;edges_w_names&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;&lt;span class="n"&gt;target&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;edges_w_names&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;as.numeric&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;edges_w_names&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;code&gt;edges_w_names&lt;/code&gt; is a three column data.frame that looks as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nf"&gt;head&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;edges_w_names&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
           &lt;span class="n"&gt;source&lt;/span&gt;          &lt;span class="n"&gt;target&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;
&lt;span class="m"&gt;1&lt;/span&gt;        &lt;span class="n"&gt;Napoleon&lt;/span&gt;          &lt;span class="n"&gt;Myriel&lt;/span&gt;     &lt;span class="m"&gt;1&lt;/span&gt;
&lt;span class="m"&gt;2&lt;/span&gt; &lt;span class="n"&gt;Mlle.Baptistine&lt;/span&gt;          &lt;span class="n"&gt;Myriel&lt;/span&gt;     &lt;span class="m"&gt;8&lt;/span&gt;
&lt;span class="m"&gt;3&lt;/span&gt;    &lt;span class="n"&gt;Mme.Magloire&lt;/span&gt;          &lt;span class="n"&gt;Myriel&lt;/span&gt;    &lt;span class="m"&gt;10&lt;/span&gt;
&lt;span class="m"&gt;4&lt;/span&gt;    &lt;span class="n"&gt;Mme.Magloire&lt;/span&gt; &lt;span class="n"&gt;Mlle.Baptistine&lt;/span&gt;     &lt;span class="m"&gt;6&lt;/span&gt;
&lt;span class="m"&gt;5&lt;/span&gt;    &lt;span class="n"&gt;CountessdeLo&lt;/span&gt;          &lt;span class="n"&gt;Myriel&lt;/span&gt;     &lt;span class="m"&gt;1&lt;/span&gt;
&lt;span class="m"&gt;6&lt;/span&gt;        &lt;span class="n"&gt;Geborand&lt;/span&gt;          &lt;span class="n"&gt;Myriel&lt;/span&gt;     &lt;span class="m"&gt;1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now we convert from the character name matrix in Triplet representation into a fully dense matrix object. In order to do this we make use of the &lt;code&gt;graph.data.frame&lt;/code&gt; object from the igraph package. The &lt;code&gt;get.adjacency&lt;/code&gt; function is builds a dense matrix from the igraph object. Because the edges in our network are un-directed the adjacency matrix will be a symmetric matrix&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;gdf&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;graph.data.frame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;edges_w_names&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;directed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;F&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;adj_mat&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;get.adjacency&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gdf&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sparse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;F&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attr&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;value&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now we have the igraph &lt;code&gt;gdf&lt;/code&gt; object, we can use it to detect communities in our network. There are several clustering routines built into igraph. Here we use the &lt;code&gt;cluster_infomap&lt;/code&gt; function which returns amongst other things an object containing membership attributes for each node in the graph&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# cluster graph&lt;/span&gt;
&lt;span class="n"&gt;members&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="n"&gt;igraph&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="nf"&gt;cluster_infomap&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gdf&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;&lt;span class="n"&gt;membership&lt;/span&gt;
&lt;span class="c1"&gt;# how many communities are there&lt;/span&gt;
&lt;span class="n"&gt;n_cluster&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;length&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;unique&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;members&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="c1"&gt;# reorder accordign to cluster memberships&lt;/span&gt;
&lt;span class="n"&gt;adj_mat&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="n"&gt;adj_mat&lt;/span&gt;&lt;span class="nf"&gt;[order&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;members&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="nf"&gt;order&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;members&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="n"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now we're ready to create the actual plot. I've added comments into the code below to try and better explain what's happening&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# open a png handle&lt;/span&gt;
&lt;span class="nf"&gt;png&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;lesmis.png&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;7000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;7000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# set up plot parameters&lt;/span&gt;
&lt;span class="nf"&gt;par&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bg&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;black&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;mar&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;50&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;50&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;50&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;50&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    &lt;span class="n"&gt;family&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Roboto Light&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;col&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;white&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;col.main&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;white&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;ps&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;300&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# create an empty plot (use axis=F so we can customise axis later)&lt;/span&gt;
&lt;span class="nf"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;axes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;F&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
     &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
     &lt;span class="n"&gt;type&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;n&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
     &lt;span class="n"&gt;xlim&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nf"&gt;ncol&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;adj_mat&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt;
     &lt;span class="n"&gt;ylim&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nf"&gt;ncol&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;adj_mat&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt;
     &lt;span class="n"&gt;main&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Les Misérables Co-occurance Matrix&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# define community colours&lt;/span&gt;
&lt;span class="n"&gt;cluster_cols&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;categorical_pal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_cluster&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# iterate over each row and column of adjacency matrix and draw rectangles onto the plot&lt;/span&gt;
&lt;span class="nf"&gt;lapply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="nf"&gt;nrow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;adj_mat&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="nf"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nf"&gt;lapply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="nf"&gt;ncol&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;adj_mat&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="nf"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="c1"&gt;# each entry in matrix is an edge so if communities differ pick the smallest&lt;/span&gt;
    &lt;span class="n"&gt;cluster_no&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;sort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;members&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="n"&gt;[j]&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nf"&gt;sort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;members&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="n"&gt;[i]&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# draw squares on the plot&lt;/span&gt;
    &lt;span class="nf"&gt;rect&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
      &lt;span class="n"&gt;xleft&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="m"&gt;.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="n"&gt;xright&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="m"&gt;.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="n"&gt;ytop&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="m"&gt;.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="n"&gt;ybottom&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="m"&gt;.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="n"&gt;pch&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;+&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="n"&gt;cex&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nf"&gt;ifelse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;adj_mat[i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;j]&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;black&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cluster_cols[cluster_no]&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="p"&gt;)})&lt;/span&gt;
&lt;span class="p"&gt;})&lt;/span&gt;

&lt;span class="c1"&gt;# draw the x and y axis with the character names&lt;/span&gt;
&lt;span class="nf"&gt;axis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tick&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;T&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;side&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;colnames&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;adj_mat&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;at&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="nf"&gt;nrow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;adj_mat&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;col&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;white&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;col.ticks&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;white&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;col.axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;white&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;las&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cex.axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0.2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nf"&gt;axis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tick&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;T&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;side&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;rownames&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;adj_mat&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;at&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="nf"&gt;ncol&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;adj_mat&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;col&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;white&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;col.ticks&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;white&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;col.axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;white&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;las&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cex.axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0.2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# add a grid to the plot&lt;/span&gt;
&lt;span class="nf"&gt;abline&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;h&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="nf"&gt;ncol&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;adj_mat&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="nf"&gt;ncol&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;adj_mat&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;lty&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# close the plot device (i.e. write the png to disk)&lt;/span&gt;
&lt;span class="nf"&gt;dev.off&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We have shown how using the atomic plot functions in R we can create some nice looking visualisations of network data. The full code is available at &lt;a class="reference external" href="https://github.com/pwwooldridge/les-mis-adjacency-vis"&gt;this github repo&lt;/a&gt;&lt;/p&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="R"></category><category term="networks"></category><category term="visualisation"></category></entry><entry><title>Linear Regression from first principles</title><link href="https://peterwooldridge.me/posts/2017/Sep/12/linear_regression/" rel="alternate"></link><published>2017-09-12T21:46:00+01:00</published><updated>2017-09-12T21:46:00+01:00</updated><author><name>Peter Wooldridge</name></author><id>tag:peterwooldridge.me,2017-09-12:/posts/2017/Sep/12/linear_regression/</id><summary type="html">&lt;p&gt;Linear regression allows one to model a dependent variable with the best straight line fit to a set of predictor variables. In the simplest scenario we have a single predictor variable. This is called simple linear regression.&lt;/p&gt;
&lt;p&gt;As an example let's take the trees dataset provided by the datasets package …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Linear regression allows one to model a dependent variable with the best straight line fit to a set of predictor variables. In the simplest scenario we have a single predictor variable. This is called simple linear regression.&lt;/p&gt;
&lt;p&gt;As an example let's take the trees dataset provided by the datasets package in R. The data consists of measurements of girth, height and volume of 31 felled black cherry trees. Suppose we wish to try and predict the volume of a black cherry tree from its girth. To begin with we can plot the two variables using the following command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nf"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;trees&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;&lt;span class="n"&gt;Girth&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;trees&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;&lt;span class="n"&gt;Volume&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;xlab&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Girth (inches)&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ylab&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Volume (cubic feet)&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="figure"&gt;
&lt;img alt="" src="https://peterwooldridge.me/posts/2017/Sep/12/linear_regression/tree_girths.png" /&gt;
&lt;/div&gt;
&lt;p&gt;The data certainly looks to have a linear relationship. A straight line equation in 2 dimensions can be defined by two variables namely the slope and intercept. Different choices for these parameters will produce different best fit lines as shown in the plot below:&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img alt="" src="https://peterwooldridge.me/posts/2017/Sep/12/linear_regression/possible_linear_fits.png" /&gt;
&lt;/div&gt;
&lt;p&gt;The left hand figure above shows linear fits with varying slopes and a fixed intercept. The right hand figure shows linear fits with varying intercepts and constant slopes. We want to find the combination of parameters for which our line best fits the data.&lt;/p&gt;
&lt;p&gt;We'll return back to the trees example but suppose that in general we observe &lt;span class="math"&gt;\(n\)&lt;/span&gt; pairs of data points &lt;span class="math"&gt;\((x_1, y_1), (x_2, y_2),\ldots, (x_n, y_n)\)&lt;/span&gt; for &lt;span class="math"&gt;\(i = 1,2,\ldots n\)&lt;/span&gt;. We can define a linear relationship by writing each observation pair as follows:&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(y_i = \beta_1 x_i + \beta_0 + \epsilon_i \qquad i = 1,2,\ldots n \tag{2}\label{2}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\beta_0\)&lt;/span&gt; and &lt;span class="math"&gt;\(\beta_1\)&lt;/span&gt; represent the slope and intercept respectively of our straight line fit. The &lt;span class="math"&gt;\(\epsilon_i\)&lt;/span&gt; are called residuals and represent the random variation of the &lt;span class="math"&gt;\(y_i\)&lt;/span&gt; around the straight line fit. Thought of another way each &lt;span class="math"&gt;\(\epsilon_i\)&lt;/span&gt; is the error between the true value of our response variable &lt;span class="math"&gt;\(y_i\)&lt;/span&gt; and the prediction given by our linear regression.&lt;/p&gt;
&lt;p&gt;We wish to find an intercept/slope &lt;span class="math"&gt;\((\beta_0, \beta_1)\)&lt;/span&gt; combination that minimises the &lt;span class="math"&gt;\(\epsilon_i\)&lt;/span&gt; for &lt;span class="math"&gt;\(i = 1,2,\ldots n\)&lt;/span&gt; meaning that our prediction errors are small. The most popular method of achieving this is to compute the sum of the squares of the residuals for &lt;span class="math"&gt;\(i = 1,2,\ldots n\)&lt;/span&gt; and choose values of &lt;span class="math"&gt;\(\beta_0\text{ and }\beta_1\)&lt;/span&gt; that minimise this quanity. Mathematically we can write the residual sum of square (RSS) as follows:&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(RSS = \sum_{i=1}^n \epsilon_i^2 \tag{3}\label{3}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;rearranging &lt;span class="math"&gt;\(\eqref{2}\)&lt;/span&gt; to make &lt;span class="math"&gt;\(\epsilon_i\)&lt;/span&gt; the subject:&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\epsilon_i = y_i - \beta_1 x_i - \beta_0 \tag{4}\label{4}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;substituting &lt;span class="math"&gt;\(\eqref{4}\)&lt;/span&gt; into &lt;span class="math"&gt;\(\eqref{3}\)&lt;/span&gt; we get:&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(RSS = \sum_{i=1}^n (y_i - \beta_1 x_i - \beta_0)^2 \tag{5}\label{5}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;To minimise &lt;span class="math"&gt;\(\eqref{5}\)&lt;/span&gt; we differentiate &lt;span class="math"&gt;\(RSS\)&lt;/span&gt; with respect to both &lt;span class="math"&gt;\(\beta_0\)&lt;/span&gt; and &lt;span class="math"&gt;\(\beta_1\)&lt;/span&gt; set the resulting quantity equal to zero and solve the two equations.&lt;/p&gt;
&lt;p&gt;We can make use of the chain rule which states that for a composite function of the form:&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
&amp;amp; F(x) = f(g(x)) \\
\end{align*}
&lt;/div&gt;
&lt;p&gt;the deriviate is given by&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(F'(x) = f'(g(x)) g'(x) \tag{6}\label{6}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Applying &lt;span class="math"&gt;\(\eqref{6}\)&lt;/span&gt; to &lt;span class="math"&gt;\(\eqref{5}\)&lt;/span&gt; we get:&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\frac{\partial RSS}{\partial \beta_0} = -2 \sum_{i=1}^n (y_i - \beta_1 x_i - \beta_0) \label{7}\tag{7}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\frac{\partial RSS}{\partial \beta_1} = -2 \sum_{i=1}^n x_i (y_i - \beta_1 x_i - \beta_0) \label{8}\tag{8}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We set the above equations equal to zero and solve for &lt;span class="math"&gt;\(\beta_0\)&lt;/span&gt; and &lt;span class="math"&gt;\(\beta_1\)&lt;/span&gt; to find the minima. Starting with &lt;span class="math"&gt;\(\eqref{7}\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
&amp;amp; 0 = -2 \sum_{i=1}^n (y_i - \beta_1 x_i - \beta_0) \\
&amp;amp; 0 = \sum_{i=1}^n (y_i - \beta_1 x_i - \beta_0) \\
&amp;amp; 0 = \sum_{i=1}^n y_i - \beta_1 \sum_{i=0}^n x_i -n \beta_0 \\
&amp;amp; n \beta_0 = \sum_{i=1}^n y_i - \beta_1 \sum_{i=1}^n x_i
\end{align*}
&lt;/div&gt;
&lt;p&gt;making use of &lt;span class="math"&gt;\(\bar{x} = \frac{\sum_{i=1}^n x_i}{n}\)&lt;/span&gt; and &lt;span class="math"&gt;\(\bar{y} = \frac{\sum_{i=1}^n y_i}{n}\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
&amp;amp; \beta_0 = \bar{y} - \beta_1 \bar{x} \label{9}\tag{9} \\
\end{align*}
&lt;/div&gt;
&lt;p&gt;Now we repeat the same process for &lt;span class="math"&gt;\(\beta_{1}\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
&amp;amp; 0 = -2 \sum_{i=1}^n x_i (y_i - \beta_1 x_i - \beta_0) \\
&amp;amp; 0 = \sum_{i=1}^n x_i (y_i - \beta_1 x_i - \beta_0)
\end{align*}
&lt;/div&gt;
&lt;p&gt;substituting in the value for &lt;span class="math"&gt;\(\beta_0\)&lt;/span&gt; obtained in &lt;span class="math"&gt;\(\eqref{9}\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
&amp;amp; 0 = -2 \sum_{i=1}^n x_i (y_i - \beta_1 x_i - \bar{y} + \beta_1 \bar{x}) \\
&amp;amp; 0 = \sum_{i=1}^n x_i (y_i - \bar{y}) + \beta_1 \sum_{i=1}^n x_i (\bar{x} - x_i) \\
\\
&amp;amp; \beta_1 = \frac{-\sum_{i=1}^n x_i(y_i - \bar{y})}{\sum_{i=1}^n x_i(\bar{x} - x_i)} \\
\\
&amp;amp; \beta_1 = \frac{-\sum_{i=1}^n (x_i y_i - x_i \bar{y})}{\sum_{i=1}^n (x_i \bar{x} - x_i^2)} \\
\\
&amp;amp; \beta_1 = \frac{\bar{y} \sum_{i=1}^n x_i - \sum_{i=1}^N x_i y_i}{\sum_{i=1}^n x_i - \sum_{i=1}^n x_i^2} \\
\\
&amp;amp; \beta_1 = \frac{n \bar{x} \bar{y} - \sum_{i=1}^n x_i y_i}{n \bar{x}^2 - \sum_{i=1}^n x_i^2}
\end{align*}
&lt;/div&gt;
&lt;p&gt;We have now derived least squares estimates for &lt;span class="math"&gt;\(\beta_0\)&lt;/span&gt; and &lt;span class="math"&gt;\(\beta_1\)&lt;/span&gt; using simple linear regression. Armed with these we can generate parameter estimates for the cherry tree regression:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;nrow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;trees&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;x_bar&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;trees&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;&lt;span class="n"&gt;Girth&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;y_bar&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;trees&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;&lt;span class="n"&gt;Volume&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;xi_yi_sum&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;trees&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;&lt;span class="n"&gt;Girth&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;trees&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;&lt;span class="n"&gt;Volume&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;xi_squared_sum&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;trees&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;&lt;span class="n"&gt;Girth&lt;/span&gt; &lt;span class="n"&gt;^&lt;/span&gt; &lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;beta_1&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;x_bar&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;y_bar&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;xi_yi_sum&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;x_bar^2&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;xi_squared_sum&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;beta_0&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="n"&gt;y_bar&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;beta_1&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;x_bar&lt;/span&gt;

&lt;span class="n"&gt;beta_1&lt;/span&gt;
&lt;span class="n"&gt;[1]&lt;/span&gt; &lt;span class="m"&gt;5.065856&lt;/span&gt;
&lt;span class="n"&gt;beta_0&lt;/span&gt;
&lt;span class="n"&gt;[1]&lt;/span&gt; &lt;span class="m"&gt;-36.94346&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Ofcourse R has a built in function (lm) to build a linear regression. We can use this function to compare the estimates we produced above:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;fit&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;lm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;trees&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;&lt;span class="n"&gt;Volume&lt;/span&gt;&lt;span class="o"&gt;~&lt;/span&gt;&lt;span class="n"&gt;trees&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;&lt;span class="n"&gt;Girth&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;&lt;span class="nf"&gt;coefficients&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Intercept&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="n"&gt;trees&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;&lt;span class="n"&gt;Girth&lt;/span&gt;
&lt;span class="m"&gt;-36.943459&lt;/span&gt;    &lt;span class="m"&gt;5.065856&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;which match our derived estimates.&lt;/p&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="linear models"></category><category term="R"></category></entry></feed>